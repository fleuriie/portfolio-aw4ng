---
title: Lecture 15 - Critique of Ashi Kamra's Blog
layout: doc
---

# Lecture 15 - Critique of Ashi Kamra's Blog

I think Ashi brought up a really important point, and one I've been thinking about a lot myself: how do we determine *if* we should do something, rather than *should* we do something? A lot of tech development has been focused around the guiding principle of "move fast and break things." As discussed in lecture, sometimes this means that developers can lose focus on what the purpose of their work is in the first place (that is, they focus more on the speed rather than the direction). Ashi points out that this philosophy fails to question whether more is always better -- is more technology always better? Is technological development always good?

I think the answer to this is incredibly complicated. Certainly, technology such as 3D printers can be incredibly helpful to help mass-produce medical devices such as [custom prosthetics](https://www.sciencedirect.com/science/article/pii/S1751616123002837) that would be prohibitively expensive to obtain before the technology. Conversely, 3D printing has also been used to produce [weaponry and guns](https://gnet-research.org/2023/02/20/assessing-the-impact-of-3d-printed-weapons-on-the-violent-extremist-milieu/) at a low cost and without much regulation. To expand upon the example Ashi brought up, AI and machine learning have been invaluable to the development of automatic transcription (like Ava, which was mentioned in lecture) and AI assistants that can help the elderly perform tasks in their homes; it has also led to the use of creatives' work without their consent and the ability for tech companies to gather more of our personal data than ever before.

The million-dollar question is 'Can we get the benefits of this technology without risking the drawbacks?' and in my opinion, the answer to this is no. It's definitely true that we shouldn't default to technology as the solution to every problem, but I don't think we should reject technological development for fear of the risks involved. I tend to be of the opinion that 'if we don't develop it, someone will,' and it's much more responsible to develop guidelines and strategies for dealing with the problems new technologies bring than to refrain from interacting with it (I don't think this is what Ashi is arguing at all, to be clear!). Thus, in response to Ashi's question of "should we fight fire with fire?" I would argue that we shouldn't be overly wary of doing so just because we are afraid of supporting the development of technologies that could be used for bad. Instead, we should focus more on making sure that regulations are in place that can prevent such misuse in the first place.